{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTYD using RAG\n",
    "\n",
    "#### RAG:\n",
    "https://python.langchain.com/docs/use_cases/question_answering/ \n",
    "\n",
    "#### PDF Loader:\n",
    "https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docs class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader \n",
    "\n",
    "####################################\n",
    "#                                  #\n",
    "####################################\n",
    "class pdf_doc:\n",
    "#private---------------------------------\n",
    "    _doc = \"\"\n",
    "    _doc_title = \"\"\n",
    "    _number_of_pages = \"\"\n",
    "    _text_extract = []\n",
    "\n",
    "\n",
    "#public----------------------------------\n",
    "    def __init__(self, path, doc_title):\n",
    "        self._doc = PdfReader(path)\n",
    "        self._doc_title = doc_title\n",
    "        self._number_of_pages = len(self._doc.pages)\n",
    "\n",
    "        for i in range(self._number_of_pages):\n",
    "            self._text_extract.append(self._doc.pages[i].extract_text())\n",
    "    \n",
    "    def g_number_of_pages(self):\n",
    "        return self._number_of_pages\n",
    "\n",
    "    def g_page_text(self, page_number):\n",
    "        return self._text_extract[page_number]\n",
    "\n",
    "    def g_title(self):\n",
    "        return self._doc_title\n",
    "####################################\n",
    "#                                  #\n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docs manager class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "####################################\n",
    "#                                  #\n",
    "####################################\n",
    "class doc_manager:\n",
    "#private---------------------------\n",
    "    _docs = []\n",
    "    _path = \"\"\n",
    "\n",
    "#public----------------------------\n",
    "    def __init__(self, path):\n",
    "        self._path = path\n",
    "\n",
    "        for file in os.listdir(self._path):\n",
    "            if file.endswith(\".pdf\"):\n",
    "                self._docs.append(pdf_doc(os.path.join(self._path, file), file))\n",
    "\n",
    "    def g_docs_length(self):\n",
    "        return len(self._docs)\n",
    "    \n",
    "    def g_doc_title(self, index):\n",
    "        return self._docs[index].g_title()\n",
    "    \n",
    "    def process_data_to_text(self):\n",
    "        text = \"\"\n",
    "\n",
    "        for doc in self._docs:\n",
    "            for i in range(doc.g_number_of_pages()):\n",
    "                text += doc.g_page_text(i)\n",
    "        \n",
    "        return text\n",
    "\n",
    "####################################\n",
    "#                                  #\n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# a class to parse text to tje console and/or to a directory#\n",
    "#############################################################\n",
    "class parser:\n",
    "\n",
    "#private-----------------------------------------------------\n",
    "    #default path to the data directory\n",
    "    __default_path = \"data\"\n",
    "    #path to the data directory. it is _default_path by default\n",
    "    __path = __default_path\n",
    "    #name when writing or creating a text file\n",
    "    __file_name = \"test_file\"\n",
    "    #index that tracks the new files\n",
    "    __index = 1\n",
    "\n",
    "#public------------------------------------------------------\n",
    "    \n",
    "# s_ prefix stands for a setter function\n",
    "\n",
    "    #sets the path\n",
    "    @staticmethod\n",
    "    def s_default_path(path):\n",
    "        parser.__path = path\n",
    "\n",
    "    #sets the file name\n",
    "    @staticmethod\n",
    "    def s_file_name(name):\n",
    "         parser.__file_name = name\n",
    "    \n",
    "    #resets the index for p_new_files() method\n",
    "    @staticmethod\n",
    "    def s_reset_index():\n",
    "        parser.__index = 0\n",
    "\n",
    "# p_ prefix stands for a printing function\n",
    "    #prints to console\n",
    "    @staticmethod\n",
    "    def p_console(data):\n",
    "        print(data)\n",
    "\n",
    "    #appends text to a text file. creates a new file is it doesnt exists \n",
    "    @staticmethod\n",
    "    def p_append_file(data, dir = __path, file_name = __file_name):\n",
    "        file_exists = os.path.exists(f\"{dir}/{file_name}.txt\")\n",
    "\n",
    "        if file_exists :\n",
    "            f = open(f\"{dir}/{file_name}.txt\", \"a\")\n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "        else:\n",
    "            f = open(f\"{dir}/{file_name}.txt\", \"x\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "    \n",
    "    #overites an existing file. creates a new file is it doesnt exists \n",
    "    @staticmethod\n",
    "    def p_overwrite_file(data, dir = __path, file_name = __file_name ):\n",
    "        file_exists = os.path.exists(f\"{dir}/{file_name}.txt\")\n",
    "\n",
    "        if file_exists :\n",
    "            f = open(f\"{dir}/{file_name}.txt\", \"w\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "        else:\n",
    "            f = open(f\"{dir}/{file_name}.txt\", \"x\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "\n",
    "    #will create a new file and write to it every time this function is called\n",
    "    #WARNING!!! - it will overwrite if the files allready exists\n",
    "    @staticmethod\n",
    "    def p_new_files(data, dir = __path, file_name = __file_name):\n",
    "        file_exists = os.path.exists(f\"{dir}/{file_name}_{parser.__index}.txt\")\n",
    "        \n",
    "        if file_exists:\n",
    "            f = open(f\"{dir}/{file_name}_{parser.__index}.txt\", \"w\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "        else:\n",
    "            f = open(f\"{dir}/{file_name}_{parser.__index}.txt\", \"x\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "\n",
    "        parser.__index += 1\n",
    "\n",
    "    #clears a file of its data\n",
    "    @staticmethod\n",
    "    def clear_file(dir = __path, file_name = __file_name ):\n",
    "        file_exists = os.path.exists(f\"{dir}/{file_name}.txt\")\n",
    "\n",
    "        if file_exists :\n",
    "            f = open(f\"{dir}/{file_name}.txt\", \"x\")\n",
    "            f.write(\"\")\n",
    "            f.close()\n",
    "        else :\n",
    "            raise Exception(\"file that you are trying to clear doesnt exists\")\n",
    "###############################################################\n",
    "# end of the parser class                                     #\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTYD class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "####################################\n",
    "#                                  #\n",
    "####################################\n",
    "class ttyd:\n",
    "#private---------------------------------\n",
    "    __llm = Ollama(temperature= 0.9, model=\"mistral\")\n",
    "    \n",
    "    __promt_give_sumary = PromptTemplate(\n",
    "        input_variables=[\"data\"],\n",
    "        template=\"give me a sumary of this data: {data}\"\n",
    "    )\n",
    "\n",
    "    __promt_user_input = PromptTemplate(\n",
    "        input_variables=[\"data\", \"question\"],\n",
    "        template=\"answer the question regarding to the data. data: {data}, question: {question}\"\n",
    "    )\n",
    "\n",
    "#public----------------------------------\n",
    "    def __init__(self, path):\n",
    "        self.__data_path = path\n",
    "        self.__file_manager = doc_manager(self.__data_path)\n",
    "\n",
    "        self.__raw_data_text = self.converte_data_to_text()\n",
    "    \n",
    "    def g_document_count(self):\n",
    "        return self.__file_manager.g_docs_length()\n",
    "        \n",
    "    def dict_to_str(dict):\n",
    "        return str(dict.get('text'))\n",
    "    \n",
    "    def generate_summary(self):\n",
    "        chain = LLMChain(llm=self.__llm, prompt=self.__promt_give_sumary)\n",
    "        return self.dict_to_str(chain.invoke(self.__raw_data_text))\n",
    "    \n",
    "    def talk_to_data(self, question):\n",
    "        chain = LLMChain(llm=self.__llm, prompt=self.__promt_user_input)\n",
    "        dict = chain.invoke(input={'data': self.__raw_data_text, 'question' : question})\n",
    "        return dict\n",
    "    \n",
    "    def converte_data_to_text(self):\n",
    "        return self.__file_manager.process_data_to_text()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "####################################\n",
    "#                                  #\n",
    "####################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Penny's Herbs & More is a small business producing and selling high-quality culinary and medicinal herbs at local farmers markets. The founders, Penny Lane and Rose Thorn, have extensive experience in herb gardening and are working towards USDA Certified Organic status. Their customers can buy select, custom cut and bundled herbs, ensuring freshness and quality. The long-term goal is to expand sales and potentially open their own retail markets.\n"
     ]
    }
   ],
   "source": [
    "def dict_to_str(dict):\n",
    "      return str(dict.get('text'))\n",
    "\n",
    "test = ttyd(\"data\")\n",
    "\n",
    "print(dict_to_str(test.talk_to_data(\"give a very brief summary\")))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
