{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTYD using RAG\n",
    "\n",
    "#### RAG:\n",
    "https://python.langchain.com/docs/use_cases/question_answering/ \n",
    "\n",
    "#### PDF Loader:\n",
    "https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docs class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader \n",
    "\n",
    "####################################\n",
    "#                                  #\n",
    "####################################\n",
    "class pdf_doc:\n",
    "#private---------------------------------\n",
    "    _doc = \"\"\n",
    "    _doc_title = \"\"\n",
    "    _number_of_pages = \"\"\n",
    "    _text_extract = []\n",
    "\n",
    "\n",
    "#public----------------------------------\n",
    "    def __init__(self, path, doc_title):\n",
    "        self._doc = PdfReader(path)\n",
    "        self._doc_title = doc_title\n",
    "        self._number_of_pages = len(self._doc.pages)\n",
    "\n",
    "        for i in range(self._number_of_pages):\n",
    "            self._text_extract.append(self._doc.pages[i].extract_text())\n",
    "    \n",
    "    def g_number_of_pages(self):\n",
    "        return self._number_of_pages\n",
    "\n",
    "    def g_page_text(self, page_number):\n",
    "        return self._text_extract[page_number]\n",
    "\n",
    "    def g_title(self):\n",
    "        return self._doc_title\n",
    "####################################\n",
    "#                                  #\n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docs manager class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "####################################\n",
    "#                                  #\n",
    "####################################\n",
    "class doc_manager:\n",
    "#private---------------------------\n",
    "    _docs = []\n",
    "    _path = \"\"\n",
    "\n",
    "#public----------------------------\n",
    "    def __init__(self, path):\n",
    "        self._path = path\n",
    "\n",
    "        for file in os.listdir(self._path):\n",
    "            if file.endswith(\".pdf\"):\n",
    "                self._docs.append(pdf_doc(os.path.join(self._path, file), file))\n",
    "\n",
    "    def g_docs_length(self):\n",
    "        return len(self._docs)\n",
    "    \n",
    "    def g_doc_title(self, index):\n",
    "        return self._docs[index].g_title()\n",
    "    \n",
    "    def process_data_to_text(self):\n",
    "        text = \"\"\n",
    "\n",
    "        for doc in self._docs:\n",
    "            for i in range(doc.g_number_of_pages()):\n",
    "                text += doc.g_page_text(i)\n",
    "        \n",
    "        return text\n",
    "\n",
    "####################################\n",
    "#                                  #\n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# a class to parse text to tje console and/or to a directory#\n",
    "#############################################################\n",
    "class parser:\n",
    "\n",
    "#private-----------------------------------------------------\n",
    "    #default path to the data directory\n",
    "    __default_path = \"data\"\n",
    "    #path to the data directory. it is _default_path by default\n",
    "    __path = __default_path\n",
    "    #name when writing or creating a text file\n",
    "    __file_name = \"test_file\"\n",
    "    #index that tracks the new files\n",
    "    __index = 1\n",
    "\n",
    "#public------------------------------------------------------\n",
    "    \n",
    "# s_ prefix stands for a setter function\n",
    "\n",
    "    #sets the path\n",
    "    @staticmethod\n",
    "    def s_default_path(path):\n",
    "        parser.__path = path\n",
    "\n",
    "    #sets the file name\n",
    "    @staticmethod\n",
    "    def s_file_name(name):\n",
    "         parser.__file_name = name\n",
    "    \n",
    "    #resets the index for p_new_files() method\n",
    "    @staticmethod\n",
    "    def s_reset_index():\n",
    "        parser.__index = 0\n",
    "\n",
    "# p_ prefix stands for a printing function\n",
    "    #prints to console\n",
    "    @staticmethod\n",
    "    def p_console(data):\n",
    "        print(data)\n",
    "\n",
    "    #appends text to a text file. creates a new file is it doesnt exists \n",
    "    @staticmethod\n",
    "    def p_append_file(data, dir = __path, file_name = __file_name):\n",
    "        file_exists = os.path.exists(f\"{dir}/{file_name}.txt\")\n",
    "\n",
    "        if file_exists :\n",
    "            f = open(f\"{dir}/{file_name}.txt\", \"a\")\n",
    "            f.write(\"\\n\\n\\n\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "        else:\n",
    "            f = open(f\"{dir}/{file_name}.txt\", \"x\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "    \n",
    "    #overites an existing file. creates a new file is it doesnt exists \n",
    "    @staticmethod\n",
    "    def p_overwrite_file(data, dir = __path, file_name = __file_name ):\n",
    "        file_exists = os.path.exists(f\"{dir}/{file_name}.txt\")\n",
    "\n",
    "        if file_exists :\n",
    "            f = open(f\"{dir}/{file_name}.txt\", \"w\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "        else:\n",
    "            f = open(f\"{dir}/{file_name}.txt\", \"x\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "\n",
    "    #will create a new file and write to it every time this function is called\n",
    "    #WARNING!!! - it will overwrite if the files allready exists\n",
    "    @staticmethod\n",
    "    def p_new_files(data, dir = __path, file_name = __file_name):\n",
    "        file_exists = os.path.exists(f\"{dir}/{file_name}_{parser.__index}.txt\")\n",
    "        \n",
    "        if file_exists:\n",
    "            f = open(f\"{dir}/{file_name}_{parser.__index}.txt\", \"w\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "        else:\n",
    "            f = open(f\"{dir}/{file_name}_{parser.__index}.txt\", \"x\")\n",
    "            f.write(data)\n",
    "            f.close()\n",
    "\n",
    "        parser.__index += 1\n",
    "\n",
    "    #clears a file of its data\n",
    "    @staticmethod\n",
    "    def clear_file(dir = __path, file_name = __file_name ):\n",
    "        file_exists = os.path.exists(f\"{dir}/{file_name}.txt\")\n",
    "\n",
    "        if file_exists :\n",
    "            f = open(f\"{dir}/{file_name}.txt\", \"x\")\n",
    "            f.write(\"\")\n",
    "            f.close()\n",
    "        else :\n",
    "            raise Exception(\"file that you are trying to clear doesnt exists\")\n",
    "###############################################################\n",
    "# end of the parser class                                     #\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTYD class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "####################################\n",
    "#                                  #\n",
    "####################################\n",
    "class ttyd:\n",
    "#private---------------------------------\n",
    "    __llm = Ollama(temperature= 0.9, model=\"mistral\")\n",
    "    \n",
    "    __promt_give_sumary = PromptTemplate(\n",
    "        input_variables=[\"data\"],\n",
    "        template=\"give me a sumary of this data: {data}\"\n",
    "    )\n",
    "\n",
    "    __promt_user_input = PromptTemplate(\n",
    "        input_variables=[\"data\", \"question\"],\n",
    "        template=\"answer the question regarding to the data. data: {data}, question: {question}\"\n",
    "    )\n",
    "\n",
    "#public----------------------------------\n",
    "    def __init__(self, path):\n",
    "        self.__data_path = path\n",
    "        self.__file_manager = doc_manager(self.__data_path)\n",
    "\n",
    "        self.__raw_data_text = self.converte_data_to_text()\n",
    "    \n",
    "    def g_document_count(self):\n",
    "        return self.__file_manager.g_docs_length()\n",
    "        \n",
    "    def dict_to_str(dict):\n",
    "        return str(dict.get('text'))\n",
    "    \n",
    "    def generate_summary(self):\n",
    "        chain = LLMChain(llm=self.__llm, prompt=self.__promt_give_sumary)\n",
    "        return self.dict_to_str(chain.invoke(self.__raw_data_text))\n",
    "    \n",
    "    def talk_to_data(self, question):\n",
    "        chain = LLMChain(llm=self.__llm, prompt=self.__promt_user_input)\n",
    "        return self.dict_to_str(chain.invoke(input={'data': self.__raw_data_text, 'question' : question}))\n",
    "    \n",
    "    def converte_data_to_text(self):\n",
    "        return self.__file_manager.process_data_to_text()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "####################################\n",
    "#                                  #\n",
    "####################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ttyd.dict_to_str() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m ttyd(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtalk_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgive a very brief summary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m, in \u001b[0;36mttyd.talk_to_data\u001b[1;34m(self, question)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtalk_to_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, question):\n\u001b[0;32m     40\u001b[0m     chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__llm, prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__promt_user_input)\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__raw_data_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: ttyd.dict_to_str() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "test = ttyd(\"data\")\n",
    "\n",
    "print(test.talk_to_data(\"give a very brief summary\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
